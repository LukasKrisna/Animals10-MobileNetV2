# -*- coding: utf-8 -*-
"""Submission_Akhir_Klasifikasi_Gambar_Lukas_Krisna.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n4jqZlkieNdL9gCw7MXsWzvkKA5O_Nsc

# Proyek Klasifikasi Gambar: Animals-10
- **Nama:** Lukas Krisna
- **Email:** lukaskrisnaaa@gmail.com
- **ID Dicoding:** lukas420

[Dataset](https://www.kaggle.com/datasets/alessiocorrado99/animals10) berisi 28.000 gambar hewan dengan 10 kelas: dog, cat, horse, spyder, butterfly, chicken, sheep, cow, squirrel, elephant. Proyek klasifikasi gambar ini menggunakan metode transfer learning dengan model [MobileNetV2](https://arxiv.org/pdf/1801.04381) yang telah dilatih sebelumnya dan menambahkan lapisan khusus untuk mencapai akurasi yang tinggi.

## Import Semua Packages/Library yang Digunakan
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
import zipfile
from google.colab import drive
import glob
import cv2

"""## Data Preparation

### Data Loading
"""

# Mount Google Drive
drive.mount('/content/drive')

# Extract datasets.zip dari Google Drive
zip_path = '/content/drive/MyDrive/datasets_image_classification.zip'
extract_path = '/content/data'

# Direktori baru jika belum dibuat
os.makedirs(extract_path, exist_ok=True)

# Extract zip file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Datasets extracted to:", extract_path)

"""### Data Preprocessing"""

# Mengambil nama-nama kelas dari direktori
class_names = os.listdir(os.path.join(extract_path, 'datasets'))
print(f"Found {len(class_names)} classes: {class_names}")

"""#### Split Dataset"""

# Direktori baru untuk train, validation, dan test sets
data_root = '/content/data_split'
train_dir = os.path.join(data_root, 'train')
val_dir = os.path.join(data_root, 'validation')
test_dir = os.path.join(data_root, 'test')

# Direktori baru tiap kelas pada train, validation, and test
for directory in [train_dir, val_dir, test_dir]:
    os.makedirs(directory, exist_ok=True)
    for class_name in class_names:
        os.makedirs(os.path.join(directory, class_name), exist_ok=True)

# Konfigurasi awal
IMG_SIZE = 224  # MobileNetV2 default input size
BATCH_SIZE = 64
EPOCHS = 20
SPLIT_RATIO = (0.7, 0.15, 0.15)  # Rasio pembagian Train, Validation, Test

# Pembagian dan preprocess data
for class_name in class_names:
    # Ambil semua image path
    class_path = os.path.join(extract_path, 'datasets', class_name)
    image_paths = glob.glob(os.path.join(class_path, '*.*'))

    # Mengacak image path
    np.random.shuffle(image_paths)

    # Hitung indeks pembagian dari SPLIT_RATIO
    n = len(image_paths)
    train_end = int(n * SPLIT_RATIO[0])
    val_end = train_end + int(n * SPLIT_RATIO[1])

    # Pembagian data
    train_images = image_paths[:train_end]
    val_images = image_paths[train_end:val_end]
    test_images = image_paths[val_end:]

    # Menyalin gambar ke direktori masing-masing dengan preprocessing
    for subset, paths, dest_dir in [
        ('Train', train_images, os.path.join(train_dir, class_name)),
        ('Validation', val_images, os.path.join(val_dir, class_name)),
        ('Test', test_images, os.path.join(test_dir, class_name))
    ]:
        print(f"Processing {subset} images for class {class_name}...")

        for i, src_path in enumerate(paths):
            img = cv2.imread(src_path)
            if img is None:
                print(f"Warning: Could not read {src_path}")
                continue

            # Ubah BGR menjadi RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            # Resize gambar
            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))

            img = img / 255.0  # Normalize to [0,1]

            # Simpan hasil preprocessing
            dest_path = os.path.join(dest_dir, f"{os.path.basename(src_path)}")
            plt.imsave(dest_path, img)

"""#### Data Augmentation"""

# Augmentasi data untuk training set
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,         # Mengatur rentang rotasi gambar hingga 20 derajat secara acak
    width_shift_range=0.2,     # Menggeser gambar secara horizontal hingga 20% dari lebar gambar
    height_shift_range=0.2,    # Menggeser gambar secara vertikal hingga 20% dari tinggi gambar
    shear_range=0.2,           # Shear transformation dengan rentang 20%
    zoom_range=0.2,            # Zoom pada gambar dengan rentang 20%
    horizontal_flip=True,      # Membalik gambar secara horizontal
    fill_mode='nearest'        # Mengisi piksel yang hilang setelah transformasi dengan metode terdekat
)

# Atur skala pixel pada validation/test sets
val_test_datagen = ImageDataGenerator(rescale=1./255)

# Data generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

validation_generator = val_test_datagen.flow_from_directory(
    val_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_generator = val_test_datagen.flow_from_directory(
    test_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Jumlah kelas
num_classes = len(class_names)

"""## Modelling

#### Load MobileNetV2 for Transfer Learning
"""

# Inisialisasi model MobileNetV2
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))

# Kunci layer-layer pada MobileNetV2
for layer in base_model.layers:
    layer.trainable = False

"""#### Custom layers di atas pre-trained model sesuai kriteria submission"""

# Sequential model
model = Sequential()

# MobileNetV2 sebagai layer pertama
model.add(base_model)

# Kustomisasi layer di atas pre-trained model
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(GlobalAveragePooling2D())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

# Compile
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Model summary
model.summary()

"""#### Callbacks"""

# Callback untuk stop training ketika akurasi mencapai 95%
class AccuracyThresholdCallback(tf.keras.callbacks.Callback):
    def __init__(self, threshold=0.95):
        super(AccuracyThresholdCallback, self).__init__()
        self.threshold = threshold

    def on_epoch_end(self, epoch, logs=None):
        if logs.get('accuracy') >= self.threshold and logs.get('val_accuracy') >= self.threshold:
            print(f"\nReached {self.threshold*100}% accuracy on training and validation sets - stopping training!")
            self.model.stop_training = True

# Direktori untuk checkpoint
checkpoint_dir = '/content/checkpoints'
os.makedirs(checkpoint_dir, exist_ok=True)

callbacks = [
    AccuracyThresholdCallback(threshold=0.95),  # Ambang batas akurasi
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),    # Hentikan pelatihan lebih awal jika tidak ada perbaikan pada 'val_loss' selama 10 epoch
    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6),   # Kurangi learning rate jika 'val_loss' tidak membaik selama 3 epoch

    # Callback untuk menyimpan model terbaik berdasarkan akurasi validasi
    ModelCheckpoint(
        filepath=os.path.join(checkpoint_dir, 'model_{epoch:02d}_{val_accuracy:.4f}.h5'),
        save_best_only=True,
        monitor='val_accuracy',
        mode='max'
    )
]

"""#### Train Model"""

history = model.fit(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=len(validation_generator),
    callbacks=callbacks,
    verbose=1
)

"""## Evaluasi dan Visualisasi"""

# Evaluasi model pada test data
test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))
print(f"Test accuracy: {test_acc:.4f}")

"""#### Visualize Training History"""

plt.figure(figsize=(12, 4))

# Plot training & validation accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='lower right')

# Plot training & validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')

plt.tight_layout()
plt.savefig('training_metrics.png')
plt.show()

"""Grafik menunjukkan performa model selama 7 epoch. Model Accuracy menampilkan peningkatan akurasi baik pada data training (biru) maupun validation (oranye), mencapai sekitar 0.95 di epoch terakhir. Model Loss memperlihatkan penurunan kerugian yang signifikan di awal epoch, dengan fluktuasi pada data validation dan penurunan berkelanjutan pada data training.

## Konversi Model
"""

# Direktori untuk menyimpan model-model
models_dir = '/content/models'
saved_model_dir = os.path.join(models_dir, 'saved_model')
tflite_model_path = os.path.join(models_dir, 'model.tflite')
tfjs_model_dir = os.path.join(models_dir, 'tfjs_model')

os.makedirs(models_dir, exist_ok=True)
os.makedirs(saved_model_dir, exist_ok=True)
os.makedirs(tfjs_model_dir, exist_ok=True)

"""#### SavedModel format"""

tf.saved_model.save(model, saved_model_dir)
print(f"Model saved to {saved_model_dir}")

"""#### TensorFlow Lite format"""

# Mengatur optimasi untuk konversi model ke format TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# Simpan TFLite model
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)
print(f"TF-Lite model saved to {tflite_model_path}")

"""TensorFlow.js format"""

!pip install tensorflowjs

import tensorflowjs as tfjs

tfjs.converters.save_keras_model(model, tfjs_model_dir)
print(f"TensorFlow.js model saved to {tfjs_model_dir}")

"""## Inference (Optional)"""

MODEL_PATH = '/content/models/saved_model'

class_names = ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']

model = tf.saved_model.load(MODEL_PATH)

from google.colab import files

# Mengambil fungsi prediksi dari model yang disimpan
# 'serving_default' adalah tanda tangan (signature) yang digunakan untuk inferensi
predict_fn = model.signatures['serving_default']

# Fungsi upload dan prediksi
def upload_and_predict():
    print("Upload an image for prediction:")
    uploaded = files.upload()

    for filename in uploaded.keys():
        # Preprocess gambar
        image = cv2.imread(filename)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))
        image = image / 255.0

        # Mengubah bentuk gambar dari (height, width, channels) menjadi (1, height, width, channels)
        image_batch = np.expand_dims(image, axis=0)

        # Konversi menjadi tensor
        input_tensor = tf.convert_to_tensor(image_batch, dtype=tf.float32)

        # Mengambil nama input dari signature fungsi prediksi
        # structured_input_signature[1] berisi informasi tentang input
        input_name = list(predict_fn.structured_input_signature[1].keys())[0]

        # Buat prediksi
        prediction_dict = predict_fn(**{input_name: input_tensor})
        output_name = list(prediction_dict.keys())[0]
        predictions = prediction_dict[output_name].numpy()

        # Class & confidence
        predicted_class_index = np.argmax(predictions[0])
        predicted_class = class_names[predicted_class_index]
        confidence = predictions[0][predicted_class_index]

        # Visualisasi hasil
        plt.figure(figsize=(6, 6))
        plt.imshow(image)
        plt.title(f'Predicted: {predicted_class}\nConfidence: {confidence:.4f}')
        plt.axis('off')
        plt.show()

        print(f"Prediction: {predicted_class} ({confidence:.4f})")

upload_and_predict()

upload_and_predict()

upload_and_predict()

upload_and_predict()

upload_and_predict()

upload_and_predict()

upload_and_predict()

upload_and_predict()

upload_and_predict()

upload_and_predict()

# Menyimpan label kelas
labels_path = os.path.join(models_dir, 'labels.txt')
with open(labels_path, 'w') as f:
    for class_name in class_names:
        f.write(f"{class_name}\n")